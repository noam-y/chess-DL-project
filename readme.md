# â™Ÿï¸ Chess Deep Learning Project - BGU Cluster Workflow

This guide documents the setup, data management, and training workflow for the Chess Deep Learning project on the Ben-Gurion University (BGU) SLURM cluster.

## ğŸ“‹ Prerequisites

Before starting, ensure you have the following on your local machine:
1.  **VSCode**
2.  **Git** 
3.  **BGU VPN**

---

## ğŸš€ 1. Cluster Setup & Environment

### Connect via SSH
Open your terminal and connect to the cluster:
```bash
ssh <your_username>@slurm.bgu.ac.il

## Create the Conda Environment:

# 1. Load Anaconda module
module load anaconda

# 2. Create a new environment named 'chess_env'
conda create --name chess_env python=3.9 -y

# 3. Activate the environment
source activate chess_env

# 4. Install dependencies
pip install torch torchvision pandas numpy Pillow tqdm

# 5. ask for the gpu
sinteractive --qos course --part gtx1080 --gpu 1 --time 0-08:00:00
# make sure you connect via ssh to the gpu you requested.
```


---

## ğŸš€ Data management
```bash
# Navigate to the assets folder
cd ~/chess-DL-project/assets

# Create the target directory and move the zip there
mkdir -p labeled_data
mv *.zip labeled_data/
cd labeled_data

# Extract all sub-zips into their own folders
for f in *.zip; do
  dirname="${f%.zip}"      # Get filename without extension
  unzip -o "$f" -d "$dirname"  # Unzip into a folder with that name
done

# Cleanup: Remove the zip files to save space
rm *.zip
```
### Runnning the training - finally!
srun --pty -p rtx2080 --qos=course --gres=gpu:1 --mem=16G --time=1:00:00 /bin/bash
module load anaconda
source activate chess_env
python train.py --data_dir ./assets/labeled_data --epochs 1 --batch_size 4


## ğŸ“Š Evaluation

The evaluation script (`evaluate.py`) tests the trained model on a new set of augmented images. It calculates **Piece Accuracy** (percentage of correctly classified squares) and **Board Accuracy** (percentage of perfectly predicted 8x8 boards).

### Prerequisites
Before running evaluation, ensure you have:
1. A trained model file (`.pth`) saved in `checkpoints/`.
2. A test dataset generated by `board_generator.py` (default folder: `new_augmented_data`).

### Usage
Run the script from the command line, providing the path to your model checkpoint:

```bash
python evaluate.py --model_path checkpoints/model_epoch_10.pth --test_dir aug/new_augmented_data
```

## upload to git-
sh deploy.sh (from git bash!)
